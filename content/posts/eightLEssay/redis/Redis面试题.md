---
title: redis 面试题
date: 2023-04-06
tags: ["redis"]
draft: true
---
## 面试题：

### String面试与分析

考点分析：集中在String的操作和底层实现
#### 1.1 Set一个已有的数据会发生什么？

**分析：** 常用操作

**回答：**如果是同种类型的值，会覆盖原有值，同时会覆盖或者擦除键的过期时间

set命令还可以直接把key抹除，例如列表键mylist，可以直接 set mylist newlist 来覆盖这个列表键。类似隐式的del（或者unlink）mylist + set

> 什么是列表键？即key-value种value是列表

#### 1.2 浮点型在String是用什么表示？

**分析：**基础知识，String有三种编码模式，INT只针对整形，所以浮点型必然是**字符串**存储

**回答：**将浮点数放入字符串对象，先将浮点数转换成字符串值，再保存转换所得的字符串值，所以浮点数在String对象中使用字符串值表示

#### 1.3 String可以有多大？（512M）

**分析：**基础知识，需要知道明确的数值，进一步思考为什么是这个值

**回答：**一个Redis字符串最大为**512M**

> [Redis的String类型的最大长度是2^29-1 (536870911)，这是因为Redis的字符串大小限制在512M(1)](https://blog.csdn.net/pipizhen_/article/details/113308109)[。这个限制主要是出于内存管理和性能考虑。如果字符串过大，可能会导致内存使用效率低下，并且在网络传输时也会消耗更多的带宽。此外，处理大字符串也会占用更多的CPU资源。因此，Redis设计者选择了512M作为字符串的最大长度，以平衡内存使用、网络带宽和CPU资源之间的关系](https://blog.csdn.net/weixin_42348880/article/details/112357490) [from new bing chat]

#### 1.4 Redis中字符串是怎么实现的？

**分析：**分情况讲编码类型，分别应用在什么场景。EMBSTR编码和RAW编码的选择阈值（可以说版本差别，3.2之前是39，3.2版本之后是44）

**回答：**redis字符串底层是String对象，String对象有三中编码方式：INT、EMBSTR、RAW。如果存储一个整形，可以用long表示的整数就以INT编码存储；如果存字符串，当字符串长度小于等于阈值（44）就使用EMBSTR编码；如果字符串大于阈值，则使用RAW编码。

> Redis < 3.2 阈值=39，> 3.2 阈值=44

#### 1.5 为什么EMBSTR的阈值是44？（超级冷门）

**分析：**

1. redis默认使用jemalloc作为内存分配器

2. jemalloc是以64字节作为内存单元做内存分配，如果超出了64个字节就超过了一个内存单元，尽量在一个内存单元，是为了减少内存寻址，又不会消耗分配过多没用到的内存，

3. 围绕64字节的关键分界分析版本变化，Redis的字符串对象是由一个redisObject+sdshdr两部分组成，redisObject大小为4+4+24+32+64 = 128bits = 16bytes，其中的ptr是64，是为了方便各种编译器和目标平台上使用


sdshdr8占用内存大小: 1byte + 1byte + 1byte + 内联数组的大小，由于内联数组中还有一个'\0'占位一个字符，所以能用的大小为64-16(redisObject)-3(sdshdr非内容属性)-1('\0')=44

**回答：**redis是使用jemalloc内存分配器，Redis以64字节为阈值区分大小字符串

所以EMBSTR的边界数组，是受到64这个阈值影响

redis对象占用的内存大小由redisObject和sdshdr两个部分组成，redisObject占用16字节，sdshdr中已分配、已申请、标记三个字段占用了3个字节。'\0'占用了一个字节，能够存放的数据就是64 - (16 + 3 + 1) = 44

#### 1.6 为什么EMBSTR的阈值之前是39？（超级冷门）

...

#### 1.7 SDS有什么用？

**分析：**redis是C语言写的，SDS是对c字符串的封装，一般对比普遍C字符串。可以从以下的场景来描述：**计算长度，扩容，缩容，二进制存储**

**回答：三点**

1. SDS包含容量字段，O(1)时间快速返回字符串长度，相比于C字符串，需要O(n)

2. 有预留空间，在扩容时如果预留空间足够，就不需要重新分配内存，节约性能，缩容时也可以将减少的空间保留下来，后续再使用

3. 不再以'\0'作为字符串结束判断标准，二进制安全，可以更方便存储一些二进制数据。


### List面试与分析

考点分析：List是比较基础的对象，考察点集中在List**常规操作**和**底层实现**

#### 2.1 List是完全先入先出吗？

**分析：**先入先出是指只允许从尾部入队，从头出队，而LIST是一个双端操作对象，所以List不是完全的先入先出

**回答：**List是双端操作对象，所以不是完全的先入先出，List也可以后入先出

#### 2.2 怎么获取List指定范围内的数据？

**分析：**基础操作

**回答：**LRANGE命令参数为**start**和**stop**，比如一个列表有s1, s2, s3三个数据，用LRANGE 0 1 可以得到s1, s2

#### 2.3 List如何移除特定值的数据？时间复杂度是多少？

**分析：**基础操作

**回答：**LREM命令可以移除特定的数据，比如LREM key 1 aaa，就回去移除第一个List key里面的值为aaa的数据，这个操作是遍历，所以时间复杂度为O(N)

#### 2.4 List对象底层编码方式是什么？

**分析：**redis3.2版本之前和之后，List的底层编码方式是不同的，面试时对不同版本的Redis的List对象底层编码方式作出分析

**回答：**5.0.5版本，List对象的编码全部由**QUICKLIST**实现。QUICKLIST是一个压缩列表组成的双向链表，结合了ZIPLIST和LINKEDLIST两者的优点

QUICKLIST是在3.2版本之后才使用的，之前都是ZIPLIST和LINKEDLIST一起使用，元素少使用ZIPLIST，元素多使用LINKEDLIST

#### 2.5 LINKEDLIST编码下，查询节点个数的时间复杂度是多少？

分析：LINKEDLIST的表头结构：

```C
typedef struct list {
    listNode *head;
    listNode *tail;
    void *(*dup)(void *ptr);
    void *(*free)(void *ptr);
    int (*match)(void *ptr, void *key);
    unsigned long len;
} list;
```

回答：LINKEDLIST编码下，查询节点个数的时间复杂度是O(1)，因为LINKEDLIST的表头结构中定义了链表锁包含节点数量的字段len

### 压缩列表面试与分析

考点分析：压缩列表是LIST的底层数据结构，体现Redis节约内存的设计理念，考察重点集中在**压缩列表本身的概念，结合LIST的操作，以及连锁更新**

#### 3.1 ZIPLIST有什么优点？

**分析：**考察基础认识，优点最好和LINKEDLIST对比

**回答：**ZIPLIST是压缩列表，是用来节约内存的，相比于LINKEDLIST链表式设计，压缩列表的内存都是紧凑排列在一起的，这带来了几个优点：1. 节约内存，2. 方便一次性分配，3. 遍历时局部性更强

#### 3.2 ZIPLIST是怎么压缩数据？

**分析：**考察ZIPLIST数据结构，ZIPLIST本身是为了节约内存而开发的，从ZIPLIST结构入手

```Plain
<zlbytes> <zltail> <zllen> <entry> <entry> ...<entry> <zlend>

// ---><entry>
<prevlen> <encoding> <entry-data>
```

**回答：**ZIPLIST分为三个部分，结构头，数据部分，结尾标识。其中，结构头记录了字节数，起始地址距尾部节点距离，节点个数；数据部分记录了上个节点的长度、内容编码，内容本身；最后一个1字节的结尾标识。**因为ZIPLIST的结构是内存连续的，介绍了指针的开销。**

#### 3.3 ZIPLIST下List可以从后往前遍历吗？

**分析：**基石：List是一种双端数据结构，无论哪种底层编码，都需要支持从后往前遍历；阐述ZIPLIST如何做到从后往前遍历，都是在考察ZIPLIST的数据结构；ZIPLIST下的entry结构体包含了上个节点的长度，所以可以通过上一个节点的长度，找到上一个节点的起始位置，这样就实现了从后往前遍历

**回答：**可以，List是双端数据结构，无论哪种底层编码，都需要支持从后往前遍历。ZIPLIST每个节点中都保存了上一个节点的长度，所以可以用当前节点的地址减去上一个节点长度来找到上个节点起始位置，进而实现从后往前遍历

#### 3.4 ZIPLIST下List如何从前往后遍历的？

**分析：**类似上面**“ ZIPLIST下List可以从后往前遍历吗？“**的分析，ZIPLIST的entry结构中，prevlen是找到上一个节点的起始位置，entry-data是实际的内容，在encoding中，无论String还是Int都是可以知道长度信息

**回答：**可以，List是双端操作，无论哪种底层编码，都需要能够支持从前往后遍历。ZIPLIST每个节点中的encoding字段，都包含了字符串或者整形的长度信息，可以用该信息实现往后遍历

#### 3.5 在ZIPLIST数据结构下，查询节点个数的时间复杂度是多少？

回答：在ZIPLIST编码下，查询节点个数的时间复杂度是O(1)，但是可以ZIPLIST中定义的zllen字段只有2字节，所以当数据个数超过65535时，zllen字段就失效了，这时想要知道节点个数就需要使用遍历，此时时间复杂度是O(n)

#### 3.6 压缩列表插入的时间复杂度是什么？



#### 3.7 连锁更新是什么问题？



#### 3.8 如何解决连锁更新问题？



### Set面试与分析

考点分析：Set是一个无序集合对象，集中考察Set的常规操作和底层实现，底层实现中要了解编码方式，其中HASHTABLE是重中之重

#### 4.1 Set是有序的吗？

**分析：**底层原理

**回答：**Set的底层实现是整数集合或者字典，前者是有序的，后者是无序的。整体来看，不建议依赖Set的顺序

#### 4.2 如何查看Set所有成员？

**分析：**基本操作

**回答：**SMEMBERS命令可以返回，参数就是SET对象，即SMEMBER key

#### 4.3 如何查看Set中成员个数？

**分析：**基本操作

**回答：**SCARD命令即可返回，参数对象是Set对象，即SCARD key

#### 4.4 如何求两个Set的并集或交集？

**分析：**基本操作

**回答：**SINTERS可以找到第一个集合中，且后面集合都出现的元素，可以求两个Set的交集，SUNION可以求并集

#### 4.5 Set的编码方式是什么？

**分析：**Set底层使用了两种编码，一种是整数集合，另一种是字典。成员的数据结构和成员数量会触发Set更改底层编码，当Set同时满足元素都是整数且元素个数不超过512这两个条件，会使用整数集合，否则使用字典编码

```C
#define set_max_intset_entries 512
```

**回答：**Set使用整数集合和字典作为底层编码，当元素都是整数且元素个数不超过512个，会使用整数集合编码，否则使用字典编码

#### 4.6 Set为什么要用两种编码？

**分析：**从编码转换的条件进行分析，Set的底层编码从INTSET到HASHTABLE的条件是元素个数或者元素类型的变化。采用两种编码方式的原因是INTSET更节约内存，所以在小数据量时使用，而数据多起来，需要HASHTABLE的查找性能

**回答：**Set底层编码是整数集合和字典，当元素数量小并且全部是整数的时候，会使用整数集合编码，更加节约内存。元素数量变大会使用字典编码，查找元素的速度会更快

### Hash面试与分析

考点分析：Hash是字典对象，他和SET一样底层编码模式有HASHTABLE，考察点集中在Hash常规操作和底层操作，HASHTABLE是重中之重，必须会

#### 5.1 Hash是有序的吗？

**分析：**Hash的底层实现是ZIPLIST或HASHTABLE，他们都是无序的

**回答：**Hash的底层实现是ZIPLIST或者HASHTABLE，他们都是无序的，所以Hash是无序的

#### 5.2 如何查看Hash所有成员？如何查看某个成员？

**分析：**基本操作

**回答：**HGETALL可以查看所有Hash成员，HGET可以以成员为关键字，查询对应的数据

#### 5.3 如何查看Hash中成员个数？

**分析：**基本操作

**回答：**HLEN可以查看Hash中成员总数，参数就是Hash对象，即HLEN key

#### 5.4 Hash的编码方式是什么？

**分析：**Hash底层有两种编码结构，一个是ZIPLIST，另一个是HASHTABLE。ZIPLIST适用于元素比较少且单个元素长度较小的情况，这里的阈值分别是元素个数少于512个，键和值长度都小于64字节

**回答：**一个是ZIPLIST编码，一个是HASHTABLE。ZIPLIST适用于元素较少且单个元素长度较小的情况，其情况使用HASHTABLE

#### 5.5 Hash查找某个key的平均时间复杂度是多少？

**分析：**考虑多种底层编码，ZIPLIST需要遍历，平均复杂度为O(N)，HASHTABLE是字典，时间复杂度为O(1)

**回答：**HSet有两种底层结构，ZIPLIST是O(N)，HASHTALE则是O(1)

#### 5.6 Hash为什么要用两种编码方式？

**分析：**对象使用多种编码方式是Redis的一个特点...

**回答：**采用两种编码方式的原因是ZIPLIST更节约内存，所以在小数据量时使用，而数据量多，使用HASHTABLE可以提高更高的查找、更新性能。

### HASHTABLE面试与分析

考点分析：HASHTABLE是Set、Hash等数据对象的底层编码模式，面试考察集中在数据结构，渐进式扩容，扩容缩容时机等

#### 6.1 HASHTABLE查找元素总数的平均时间复杂度是多少？

**分析：**考察Redis字典的表头结构，如果表头结构中存储了对元素总数的字段，那么查找元素总数的平均时间复杂度是O(1)，而如果没有这个字段，那么字典就需要去遍历所有的键值对

redis字典的表头结构：

```C
typedef struct dictht {
    dictEntry **table;
    unsigned long size;
    unsigned long sizemask;
    unsigned long used;     // 记录当前键值对数量的字段
} dictht;
```

**回答：**HASHTABLE查找元素总数的平均时间复杂度是O(1), 因为HASHTABLE的表头结构中有存储键值对数量的字段used.

#### 6.2 一个数据在HASHTABLE中的存储位置，是怎么计算的？

**分析：**当一个新的键值对要插入到HASHTABLE中时，首先会使用哈希函数计算这个key的哈希值，Redis使用的哈希算法是murmurHash2，然后把哈希值和哈希掩码做与运算得到索引值，哈希掩码起始就是哈希数组的大小-1

**回答：**首先会通过哈希函数计算出key的哈希值，然后与哈希掩码做与运算得到索引值，索引值就是这个数据在HASHTABLE中的存储位置

#### 6.3 HASHTABLE怎么扩容？

**分析：**HASHTABLE的扩容通过渐进式rehash操作完成

**回答：**首先程序会在HASHTABLE的1号表分配空间，空间大小等于第一个大于等于0号表已使用的空间*2的2次幂（ 2^n >= used * 2 ）。在rehash进行期间，标记为rehashidx从0开始，每次对字典的键值对执行增删改查操作后，都会将rehashidx位置的数据迁移到1号表，如何将rehashidx加1，随着字典操作不断执行，最终0号表的所有键值对都会被rehash到1号表上。之后，1号表会被设置为0号表，接着1号表（原0号表）的位置创建一个新的空白表

#### 6.4 HASHTABLE怎么缩容？

**分析：**HASHTABLE的缩容也是通过rehash操作完成

**回答：**首先程序会为HASHTABLE的1号表分配空间，缩容前used如果小于最小值（最小值为4）就用最小值。如果大于最小值，就是大于原来used的最近2次方幂值

在rehash进行期间，标记位从rehashidx从0开始，每次对字典的键值对执行增删改查操作后，都会将rehashidx位置的数据迁移到1号表，如何rehashidx加1，随着字典操作的不断执行，最终0号表的所有键值对都会被rehash到1号表上，之后，1号表会被设置成0号表，接着在1号表位置创建一个新的空白表。

https://cloud.tencent.com/developer/article/1873205

加深理解HASHTABLE是怎么扩容缩容

#### 6.5 HASHTABLE扩容，缩容的时机？

**分析：**HASHTABLE的扩容与缩容由哈希表的负载因子觉得，负载因子 = 键值对数量 / 哈希表大小

**回答：**当以下两个条件中的任意一个被满足时，哈希表会自动开始扩容：

- 服务器目前没有执行BGSAVE或者BGREWRITEAOF，并且负载因子 >= 1
- 服务器目前没有执行BGSAVE或者BGREWRITEAOF，并且负载因子 >= 5

缩容：当哈希表的负载因子小于0.1时，程序会自动开始对哈希表进行缩容操作

### 跳表面试与分析

考点分析：跳表是Redis有序集合使用到的一种底层数据结构，集中考察**操作流程，数据结构，层高**

#### 7.1 跳表是什么？和普通的链表有什么区别？

**分析：**跳表本质上还是链表 ，虽然链表结构简单清晰，但是查询某个节点的效率比较低，时间复杂度为O(n)，为了提升查找的性能，Redis就引入了跳表，跳表在链表的基础上，给链表添加了多级索引，通过索引课一次实现多个节点的跳跃，提高性能（不同级别的索引对应不同的层高，积分定位时从高级索引开始检索，颗粒度有粗到细，逐步精确定位，类似二分算法的逻辑）

**回答：**跳表还是链表，不过相对于普通链表，增加了多级索引，通过索引可以实现O(logn)元素查询效率

#### 7.2 聊一聊跳表的查找过程

**分析：**基础

**回答：**从高级索引往后查找，如果下个节点的数据比目标节点小，则继续找，否则不跳过去，而是用下级索引往下查找

#### 7.3 跳表查询节点总数的平均时间复杂度是多少？

**分析：**这个问题是对Redis跳表数据结构的考察，想想跳表的表头结构

```C
typedef struct zskiplist {
    struct zskiplistNode *header, *tail;
    unsigned long length;
    int level;
} zskiplist;
```

跳表的表头结构定义了保存节点数量的字段，`length`，所以对Redis跳表查询节点总数的平均时间复杂度位`O(1)`

**回答：**在跳表编码下，查询节点总数的平均时间复杂度是O(1)，因为跳表的表头结构中定义了一个保存节点数量的字段length，源码中调用查询节点总数的API时直接返回这个字段

#### 7.4 跳表中一个节点的层高是怎么决定的？

**分析：**对跳表这种数据结构本身的考察，跳表中插入一个数据之前会选择一个随机化的层数，如果跳表的层数从下至上呈现一定的比例关系，那么后期插入和删除的时候就回去维护这种比例关系，会使时间复杂度退化。

但是生成的随机层数得遵循一个算法，使得生成小数层数的概率大，而生成大数层的概率小，这个算法是幂次定律，跳表在插入新节点的时候，选择一个随机化的层数

**回答：**跳表在插入新节点之前会计算一个随机的层高，具体来说，跳表的每一个节点一开始默认都是1层，然后没加一层的概率都是25%，在5.0.5版本最高为64层

#### 7.5 跳表插入一条数据的平均时间复杂度是多少

**分析：**考察跳表这个数据结构本身，跳表实际上就是在一位链表上建立多层索引的二维链表，多出来的层数可以让跳表实现类似二分查找的算法，所以跳表的插入平均时间复杂度是`O(logn)`

**回答：**跳表是一种支持多级索引的结构，查询效率可以媲美二分查找，它插入一条数据的平均时间复杂度是`O(logn)`

#### 7.6 跳表插入数据会影响其它节点层高吗？

**回答：**不会的，节点层高是创建时就确认好了的，不会被新插入的节点影响，新插入的节点会影响每一层前一跳、后一跳的关联指针。

### ZSet面试与分析

考点分析：

ZSet，也就是有序集合，考察集中在基本操作，编码方式，底层结构。其中跳表这个数据结构考察的频率很高

#### 8.1 ZSet如何提添加元素，如果移除元素？

分析：基本操作

回答：ZADD命令可以用于创建ZSet，也可以用于添加元素，ZREM命令可以移除元素

#### 8.2 ZSet如何从大到小查找范围？

分析：基本操作

回答：ZRANGE命令可以按分数从小到大的顺序查找范围，ZREVRANGE则是逆序

#### 8.3 ZSet底层有几种编码？

分析：基础知识考察。ZSet的底层编码可以是ZIPLIST或者skiplist+字典，需要根据不同情况说出不同的编码类型

Ziplist 和 skiplist+ 字典 编码的选择阈值不一定可以记清楚，不清楚可以说个大概

- ZSet保存的元素数量小于128

- ZSet保存的所有元素成员的长度都小于64字节


满足以上两个条件的有序集合将使用ZIPLIST，不满足则使用skiplist+字典

回答：ZSet是有序集合列表，ZSet对象的底层有两种编码发生：ZIPLIST或者skiplist + 字典。

如果一个ZSet对象中的所有元素同时满足：元素数量小于128以及所有元素成员的长度都小于64字节，则会使用ZIPLIST编码，否则使用skiplist+字典

#### 8.4 ZSet查询节点总数的平均时间复杂度是多少？

分析：

**回答：**无论是ZIPLIST编码还是SKIPLIST编码，查询节点总数的平均时间复杂度都是O(1), 因为对应结构的表头结构中都保存节点数量的字段，查询节点总数时会直接返回这个字段

#### 8.5 ZSet为什么将跳表和HashTable配合使用？

分析：使用这两种数据结构来实现ZSet，为了让有序集合拥有这两种数据结构的优势。结合各自的优势进行回答。

回答：为了结合两种数据结构各自的优势，当ZSet要根据成员来查找分支的时候，只需要使用字典来查找，时间复杂度为`O(1)`，而当ZSet要执行方位操作时，比如`ZRANK`, `ZRANGE`等命令，将使用原本就有序的跳表来实现

#### 8.6 ZSet为什么用跳表而不是B+树？



#### 8.7 ZSet为什么用跳表而不是用红黑树？



### Redis内存面试与分析

考点分析：重点考察数据到底怎么存，以及了解过期字典

#### 9.1 SET a b, 这个数据的存储结构是怎么样的？

分析：考察对内存存储的理解，在redis中，存储是一个字典结构

回答：Redis中存储是字典结构，SET a b之后，a会放进字典对应的偏移位置，b作为对应的value进行存储

#### 9.2 SET a 100 ex 60之后，调用TTL a，此时这个过期信息是存储在哪里的？

分析：考察过期时间的存储方式

回答：添加了对键a添加ttl，则会立马将key添加到过期字典中，并存储对应时间戳

#### 9.3 某个key有过期时间后，那么他即在数据字典里，又在过期字典里，这是占了2份内存？

分析：字典key存储考察

回答：无论是数据字典还是过期字典里面的key对象，实际都是存储的String对象指针，所以不会重复占用内存，Redis对内存的时候都是很珍惜的

---

### Redis单线程面试与分析

考点分析：数据命令操作各种数据对象以达到存储数据的目的，这些操作命令在Redis中具体是怎么运行的

#### 10.1 Redis是单线程还是多线程？

分析：重点点名核心处理逻辑是单线程的

回答：核心处理逻辑，Redis一直是单线程的；

某些异步流程从4.0开始用多线程，如UNLINK、FULSHALL ASYNC等非阻塞操作

网络I/O解包从6.0开始用的都是多线程

#### 10.2 Redis为什么选择单线程做核心处理？

分析：多线程复杂、成本高

回答：redis的性能瓶颈在I/O不在cpu，这种情况下，选择多线程成本和复杂度高，综合投入产出比，所以选择了单线程

#### 10.3 Redis单线程性能如何？

分析：对性能有个大概的认识

回答：非常好，2核8G的机器读性能可以达到10w/s左右，写性能也能有7, 8w/s

#### 10.4 为什么单线程还能这么快？

分析：内存、数据结构、多路复用 三个方面

回答：Redis是内存数据库，内存操作本身就很快；同时Redis选了高效的数据结构，很多对象底层有多种实现以应对不同的场景，追求性能的极致；最后redis采用了多路复用的机制，使其在网络IO操作能并发处理大量的客户端请求，实现高吞吐量



### Redis多线程面试与分析

#### 11.1 Redis6.0后引入多线程，你知道为什么吗？

分析：时代发展，为了应付大流量业务

回答：随之时代的发展，很多业务的请求量剧增，IO操作确实成为了瓶颈，比如读取请求、发送回包成了性能提升的瓶颈，所以在维持单线程框架执行Redis指令的基础上引入了多线程处理IO操作

#### 11.2 Redis6.0的多线程是默认开启的吗？

分析：基础考察

回答：不是，默认是关闭的，如果需要开启需要在Redis.conf配置文件中修改

#### 11.3 Redis6.0的多线程主要负责命令执行的哪一块？

分析：多线程的定位

回答：读取并解析指令以及回包

单线程模式下是一个线程完成读取、解析、执行、将回包放入客户端缓冲区；

但是在多线程模式下，将不同的client放入clients_pending_read任务队列中，后续通过Round-Robin轮询负载均衡策略将这些client分给其它IO线程和主线程进行读取和解析；

在回包的时候，也是利用Round-Robin轮询负载均衡策略把等待回包对了中的任务连续均匀地分配给IO线程各自的本地FIFO任务队列和主线程自己，主线程轮询所有IO线程完成回包任务

---
### 持久化基础面试题
考点分析：redis的持久化方式

#### 12.1 Redis为什么需要持久化？

分析：持久化基础考察

回答：持久化就是将内存数据存入磁盘，持久化的保存起来。**Redis虽然最多的场景是缓存，但是有时候即便是缓存也不想重启之后缓存都不在了，这样请求一下打到存储**，同时Redis本身也可以做存储，这时候就更需要持久化了

#### 12.2 RDB和AOF本质的区别是什么？

分析：本质区别还是得从RDB是使用快照进行持久化，AOF是日志这点说明

> 区别可以从文件类型，文件恢复速度，安全性 来进行回答

- 文件类型：RDB生成的是二进制文件（快照），AOF生成的是文本文件（追加日志）

- 安全性：缓存宕机时，RDB容易丢失较多的数据，AOF根据策略决定，比如可以配置每秒刷，就只丢失1s的数据

- 文件恢复速度：RDB是二进制文件，所以恢复速度比AOF快

- 操作的开销：每一次RDB保存都是一次全量保存，操作比较重，通常设置至少间隔几分钟保存一次数据。而AOF的刷盘是一次追加操作，操作起来比较轻，通常设置策略为每一秒进行一次刷盘


回答：本质区别是RDB是全量保存快照进行持久化，AOF是追加日志文件进行持久化

#### 12.3 RDB和AOF只能选一种，你选哪一种？

分析：这是一个 性能 与 可靠 之间做一个选择，没有正确答案，需要对两种持久化方式有更深的理解

回答：

1. 回答1：

    1. 如果我们能接受分钟级的数据丢失可以考虑选择RDB

    2. 需要尽量保存数据安全，可以考虑AOF、RDB一起开启

    3. 如果只用AOF，优先选择everysec策略进行刷盘

2. 回答2：

    1. 如果需要持久化，只能开启一种，我会选择RDB，这也是Redis官方推荐和默认的选择


#### 12.4 同时开启AOF和RDB，启动时加载哪个？

分析：有AOF，只会用AOF

回答：AOF和RDB同时开启，只会用AOF，即使此时AOF文件因为异常原因不存在，也不会用RDB，原因是既然开启了AOF说明你想要AOF少丢失数据的能力，所以即使没有AOF文件，也不会用RDB，这样发生异常能及时发现处理，不然后者丢失数据就是潜在危险

### RDB面试与分析

[RDB面试与分析](https://ls8sck0zrg.feishu.cn/wiki/H9X7wKUm0iCzb4kIav6ctM2unWb)

#### 13.1 RDB本质是什么？

分析：RDB就是快照，存储二进制文件

回答：RDB本质是二进制形式的快照

#### 13.2 如何触发RDB？

分析：考察对RDB的熟悉程度，同时考察回答问题的完整性

回答：RDB可以通过配置定时触发，触发时用的是后台持久化

也可以使用save、bgsave命令主动触发，save底层用的是阻塞式持久化，bgsave用的是后台持久化

最后，通过redis正常关闭，是会执行阻塞式持久化

#### 13.3 RDB对主进程有什么影响？

分析：主要从RDB的整个流程来寻找一些明显 或 潜在的风险

回答：

- 当执行的是save，阻塞式持久化的时候，由主进程进行RDB快照保存，会阻塞主进程

- 当执行后台持久化时，由fork出的子进程来进行RDB快照保存

    - 如果数据量比较大时，会导致fork子进程这个操作比较耗时，从而阻塞主进程

    - 由于采用了写时复制技术，如果进行RDB保存时，由大量的写入操作执行，会导致主进程多拷贝一份数据，消耗大量额外的内存


#### 13.4 RDB执行流程是怎样进行的？

分析：核心

![](https://rt5bap83jl.feishu.cn/space/api/box/stream/download/asynccode/?code=YTlkYjM0ZTJmOGQyN2ExOWRkZTYzMzIyYTIyOTE1MjZfbXhJeGliWVRCMnVzZFdLM0FNa1V3R2VyZzdIY1duSFpfVG9rZW46TDZyZ2IxSmNrb0xpRTd4MGVtMGNVRzJtblVkXzE3MjE4NDE1NTk6MTcyMTg0NTE1OV9WNA)

回答：

1. 首先，Fork一个子进程来专门做RDB持久化

2. 子进程写数据到临时的RDB文件

3. 用新的RDB文件替换旧的RDB文件


回答2：

![](https://rt5bap83jl.feishu.cn/space/api/box/stream/download/asynccode/?code=YzQxMmUyZmUwOTNhODMwNzk0N2RhNjY5ZDQyNzc2YjRfV3J0R1Y1dkx6S3dCUmFwenUxSVFJWXE3RnBSNEdBY0tfVG9rZW46UEh4RmJ0Z2prb0VoSDF4Q2hCYWNxMlFnblhiXzE3MjE4NDE1NTk6MTcyMTg0NTE1OV9WNA)

#### 13.5 从源码上看，RDB持久化什么时候触发？

分析：
- 从源码上，RDB持久化函数整体上在这几个地方会被使用
    - Redis shutdown（redis关闭之前会进行一次持久化
    - 客户端发送save命令
    - 客户端发送bgsave命令
    - 每一次事件循环ServerCorn检查是否需要bgsave
    - 主从全量复制发送RDB文件
	- 客户端执行数据库清空命令FLUSHALL


### AOF面试与分析

#### 14.1 AOF是默认开启的吗？

分析：AOF基础知识掌握

回答：不是，RDB默认开启，AOF是手动开启

#### 14.2 AOF重写是解决什么问题？

分析：AOF基础知识

回答：重写用于解决AOF不断膨胀问题，随着命令越来越多，AOF文件越来越多。重写就是通过当前状态，重新生成最新的AOF操作命令记录的过程

#### 14.3 简单描述AOF重写流程（很重要，务必要学）

分析：

- 将AOF重写里流程记为 “一次拷贝，两处日志”

- 一次拷贝：重写发生时，主进程会fork一个子进程，让子进程将Redis的内存数据写入到重写日志

- 两次日志：重写发生时，我们需要注意AOF缓冲和AOF重写缓冲；当重写时，有新的写入命令执行，会由主进程分别写入到AOF缓冲区和AOF重写缓冲区；AOF缓冲用于保证此时发生宕机时，原来的AOF文件也是完整的，可以用于恢复；AOF重写缓冲用于保证新的AOF文件不会丢失最新的写入操作

- 在重写时，AOF重写缓冲会通过**管道**传送给子进程，在由子进程刷入新的AOF日志


回答：

- 一次拷贝：重写发生时，主进程会fork一个子进程，子进程和主进程共享Redis物理内存，让子进程将内存写入重写日志

- 两处缓冲：当重写时，有新的写入命令执行，会有主进程分别写入AOF缓冲和AOF重写缓冲；AOF缓冲用于保证此时发生宕机，原来的AOF日志也是完整的，可以用于恢复。AOF重写缓冲用于保证新的AOF文件也不会丢失最新的写入操作


#### 14.4 AOF对主流程有什么影响？（几乎不用了解

分析：

- 明显的影响：使用AOF持久化，如果选择always的策略，每当Redis命令执行后，需要由主进程进行write + fsync操作，如果数据量过大的话，主进程就会花费较大的时间用于AOF日志，对后续请求影响较大

- 潜在的影响：

    - 如果选择everysec策略，虽然fsync是交给后台进程BIO_AOF_FSYNC来完成，但是主进程还需要进行write操作，如果后台线程上一轮fsync没有完成，那么主进程write的时候仍然会阻塞

    - AOF重写是由fork出的子进程进行的，类似于上面提到的风险，fork子进程这个操作有可能阻塞主进程


回答：

- 当appendfsync使用always，如果aof写入日志压力过大会导致主进程无法继续处理其他请求

- 当appendfsync使用everysec，如果后台线程上一轮的fsync没有完成，会导致本轮主线程执行write被阻塞

- 当AOF重写发生时，如果数据量比较大，会导致fork子进程这个操作比较耗时，从而阻塞主进程




#### 14.5 源码中，AOF刷盘什么时候会触发（可以不了解，一般不问

分析：

- AOF的流程：

      整个AOF的流程可以分为三个过程：命令追加（append到aof_buf)、文件写入（将aof_buf中的数据write进内核缓冲区page cache）、文件同步（fsync让内核缓冲区数据进入硬盘文件）

- 从源码上来看，AOF刷盘函数在三个地方触发

    - Redis shutdown的时候

    - 每一次事件循环 钩子函数 beforeSleep()

    - 每一次事件循环的时间事件对应的handler--serverCron()


回答：...根据不同的appendfsync策略回答



#### 14.6 [Redis 大 Key 对持久化有什么影响？](https://xiaolincoding.com/redis/storage/bigkey_aof_rdb.html#%E5%A4%A7-key-%E5%AF%B9-aof-%E6%97%A5%E5%BF%97%E7%9A%84%E5%BD%B1%E5%93%8D)

https://xiaolincoding.com/redis/storage/bigkey_aof_rdb.html#%E5%A4%A7-key-%E5%AF%B9-aof-%E6%97%A5%E5%BF%97%E7%9A%84%E5%BD%B1%E5%93%8D

---

### AOF优化--混合持久化面试与分析

[AOF优化面试题](https://ls8sck0zrg.feishu.cn/wiki/wikcniden2BD4RB5APQxeeb29lb)

#### 15.1 AOF混合持久化方案是什么？

分析：AOF混合持久化是在AOF重写的基础上做了一些修改，AOF文件前面存储的是RDB格式，后面存储AOF格式

回答：

- AOF混合持久化会使用RDB持久化函数，将内存数据写入到新的AOF文件中（数据格式是RDB格式）

- 而重写期间 新的写入命令追加到 新的AOF文件，仍然是AOF格式

- 新的AOF文件就是由RDB格式和AOF格式组成的日志文件


#### 15.2 为什么需要混合持久化

分析：混合持久化解决了什么问题，结合RDB跟AOF的优势

回答：混合持久化实际是AOF的优化，还是AOF记录的方式，但是在重写时候是使用子进程将当前数据库内容保存到RDB格式，写入到新AOF文件，作为前半部分，后面新增的内容是和普通的AOF时一样写入

这样做的好处就是既有RDB文件小、加载快的优势，也有AOF持久化数据损失少的优势

#### 15.3 启动加载AOF文件时，怎么判断他是否是混合持久化？

回答：混合持久化的AOF文件里开头有REDIS这个标志，加载的时候通过这个标记来进行判断

#### 15.4 AOF重写还有什么不足？

[AOF优化-MP方案(不要求看，但面试可以吹)](https://ls8sck0zrg.feishu.cn/wiki/wikcnN0BRkgwBVhqvcN2V9YmVJh)

---
### 缓存基础面试与分析

#### 16.1 Redis缓存是如何应用的？

分析：一般做旁路缓存

回答：我们是做旁路缓存，先查询Redis，没有缓存的话查询Mysql并加载数据到Redsi

#### 16.2 Redsi设置缓存用什么命令？

分析：基本命令

回答：SET命令，set key value，如果业务需要，可以再加一个EX扩展参数当过期时间

#### 16.3 聊一聊旁路模式下的查询流程

分析：通过流程考察是否理解旁路缓存

回答：请求到后台后，先查询Redis，有缓存的话就返回数据，没有就查Mysql，并将Mysql返回的数据缓存进Redis，最后返回数据给用户

### 缓存异常面试与分析

#### 17.1 缓存击穿和缓存穿透有什么区别？

分析：概念考察

回答：击穿是某个key在数据库存在而缓存不存在，被一瞬时流量击垮的场景

穿透是某个key数据库和缓存里不存在，被海量流量打击的场景

核心区别在于一个数据是有的，只是还没来得及在缓存生成，比如缓存过期；另一个是数据都不存在

#### 17.2 缓存雪崩和缓存击穿有什么区别？

分析：缓存雪崩一般是大规模key过期，穿透一般是某个key过期

回答：他们的相同点是一般都是由于key过期导致

不同点是击穿是某个热点key过期，刚好对这个key有瞬时大规模访问，雪崩是一群key同时过期，他们一起的访问量击垮数据库

#### 17.3 缓存击穿怎么解决？

分析：

1. 续期热点避免热点过期；

2. 互斥访问mysql防止击穿


回答：支持续期，让缓存能持续存在

互斥重建，发现缓存不存在，加个互斥锁，这样只有一个线程去Mysql查询并将数据加载到Redsi，其它线程等待一定时间之后重试即可

### 缓存一致性面试与分析
#### 18.1 缓存一致性是什么？

分析：基础问题

回答：Redsi作为mysql的缓存，如果数据源更新了，redsi的数据怎么保持最终一致，这就是缓存一致性

#### 18.2 Redsi做旁路缓存，如果Mysql更新了，此时何去何从？

分析：经典的缓存一致性问题，结合实际经验回答

回答：在项目中使用过期时间来兜底，并且在更新DB后删除缓存来提升一致性的方案，另外在做方案设计时候我还考虑过订阅binlog的方式，但是这种方案额外映入了消费服务，成本太高而收益不足，所以选择了前者

#### 18.3 你认为什么情况下，适合用订阅binlog的方式？

分析：虽然只有很少的团队会使用，但是它是有应用场景的

回答：这种模式更像是同步数据（实时更新），比较适合缓存很长时间过期、或者不过期的场景，比如一个视频网站，有几个展示视频，他们的基本流量很大，但是这几个视频的基本信息不动，是稳定的，就可以用这种方法

---
### 分布式锁面试与分析

#### 19.1 分布式锁实现要点是什么？（要点：加锁、解锁、怎么用？）

分析：怎么加锁、怎么解锁、怎么用

回答：加锁的时候要设置owner和过期时间，前者是便于解锁是进行拥有者判断，后者是作为异常情况的处理

解锁的时候要先判断owner，是自己的锁再释放，需要注意这两步操作的原子性，可以用lua脚本进行保证

#### 19.2 为什么需要引入owner概念？

分析：本质是问分布式锁为什么需要这种对称性，**对称性：对同一个锁，加锁和解锁必须是同一个竞争者，不能被其它竞争者持有的锁释放了（超时自动释放除外）**

回答：分布式锁需要保证对称性，假设没有这种对称性，例如服务A获得了锁，由于业务流程比较长、网络延迟、GC卡顿等原因，导致锁过期，而业务还再继续，这时，服务B拿到了锁，这时候服务A恢复过来并完成了业务，就会释放锁，而B还在继续执行，等B完成释放锁的时候释放了别人的锁，这种情况需要避免

#### 19.3 lua一定能保持原子性？

回答：lua本身不具备原子性，之所以说lua来保证原子性是因为Redis是单线程执行，一个流程放进lua来执行，相当于打包在一起，Redis执行lua的过程不会被其他请求打断，所以说保证了原子性

#### 19.4 分布式锁是完全可靠的吗？

分析：完全可靠是不存在的，因为网络不可靠，可以使用RedLock，RedLock通过集群的方式几乎可靠，但说不上完全

回答：没有完全可靠的分布式锁，在使用分布式锁的时候需要考虑这一点，关键业务需要幂等来兜底，还可以使用RedLock集群化的分布式锁，这种模式出问题的概率微乎其微

#### 19.5 RedLock是什么？

分析：理解RedLock

回答：Redis的RedLock，是集群化部署的思想，大概的思路就是多个机器，通常是奇数个，达到一半以上的同意加锁才算加锁成功，这样可靠性可以向ETCD靠拢

假设有5个Redis主节点，基本保证它们不会同时宕机，获取锁和释放锁的过程中，客户端会执行一下操作：

1. 向5个redis申请加锁

2. 只要超过一半，则加锁成功，如果超过一半失败，需要向每个redis发起解锁命令

3. 由于向5个redis发起请求，会有一定耗时，所以锁剩余持有时间，需要减去请求时间。这个可以作为获取锁失败的判断依据，如果剩余时间为0，那么也是获取锁失败

4. 使用完成之后，向5个redis发生解锁请求


这种模式的好处：如果挂了2台redis，整个集群还是可以用的，给运维更多的时间来修复

20. ### 应用场景面试题


[场景应用面试题](https://ls8sck0zrg.feishu.cn/wiki/wikcnIBe4SH09pmm8W6tP0IH9Re)
